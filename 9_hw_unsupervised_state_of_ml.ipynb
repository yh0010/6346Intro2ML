{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "9-hw-unsupervised-state-of-ml.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yh0010/NYU_Summer_Tandon_Scholar_Intro2ML/blob/main/9_hw_unsupervised_state_of_ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hKOzGxh7STIl"
      },
      "source": [
        "# Assignment: the state of machine learning and data science\n",
        "\n",
        "Summer 2021\n",
        "\n",
        "**Attribution**: this notebook is modeled after similar work by [Paige Bailey](https://twitter.com/DynamicWebPaige/status/1406250082194841601)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3fsG3CES3SS"
      },
      "source": [
        "* **Name**: \n",
        "* **Net ID**: "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOh_ZdEpS5gD"
      },
      "source": [
        "Now that we're wrapping up our survey of machine learning, you may be wondering what to do next. What are machine learning engineers and data scientists currently most excited about? What software frameworks and tools do they want to try out? Where are they going to learn new things?\n",
        "\n",
        "Of course, if you ask different people these questions, you'll get many different answers. Or, if you ask 20,000 people, you'll get 20,000 different answersâ€¦\n",
        "\n",
        "In this notebook, we'll work with the 2020 Kaggle Machine Learning & Data Science Survey.  Kaggle is an online community for machine learning and data science enthusiasts to find and share data sets and models. In their annual survey, they ask their users to answer questions about how they use machine learning and what they are looking forward to doing next.\n",
        "\n",
        "The survey results can potentially give us some insight into what's next in machine learning.\n",
        "\n",
        "Of course, you could just look at the most common answers to each question and stop there! But, that won't give us the full picture. We expect that there may be \"cohorts\" among Kaggle users who have different interests or different background: for example, there might be some respondents who use machine learning mainly for business analytics, some who use it as a hobby, some who are students, etc. Among different \"cohorts\", the most popular tools and techniques are likely to be different. \n",
        "\n",
        "Depending on which \"cohort\" you identify with most closely, the overall most common answers may not be very useful to you - you may be more interested in what other members of \"your cohort\" are doing and anticipating.\n",
        "\n",
        "In this notebook, we will use unsupervised learning methods to try and find that underlying \"cohort\" structure in the data, and use it to gain insight into the state of machine learning and data science."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT-iVmjYuT8P"
      },
      "source": [
        "## Load and install libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNdHZpEfuYJT"
      },
      "source": [
        "We'll start by loading some familiar libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec-_BVEeuVOl"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from ipywidgets import interact, fixed\n",
        "import ipywidgets as widgets\n",
        "from mpl_toolkits import mplot3d\n",
        "from matplotlib import cm, colors\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWad8m4suaW9"
      },
      "source": [
        "We'll also install a new library that's not pre-installed in Colab. This UMAP library will implement a dimensionality reduction method that we'll use later in the notebook:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8Ljw9dGuhzA"
      },
      "source": [
        "!pip install umap-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrb28ptsullp"
      },
      "source": [
        "from umap import UMAP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cda0CGVWU6t"
      },
      "source": [
        "## Read in and process data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M16JHYj1qJNu"
      },
      "source": [
        "First, download the data and the survey documentation:\n",
        "\n",
        "* [Kaggle 2020 survey data](https://drive.google.com/file/d/1fGNDBlpziYMAVHSXQJpcLd_AhrsFkVf3/view?usp=sharing)\n",
        "* [Kaggle 2020 survey questions and answer options](https://drive.google.com/file/d/1yVsd9r1E6s6qh6n5UYlLxs8mKSl5VMzC/view?usp=sharing)\n",
        "* [Kaggle 2020 methodology](https://drive.google.com/file/d/1Babng7-Ivfnf34jy5k6jdR8LAFxZuTgo/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x43sQoj8rWUM"
      },
      "source": [
        "Review the survey questions and the answer options for each question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs6ABsYxq0Gm"
      },
      "source": [
        "Upload the survey data (CSV file) to your Colab workspace:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_t_vx82q4tr"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHHD7XMarG7A"
      },
      "source": [
        "The CSV file has two header rows - one with a question number, and one with the question text. We'll read the question text into one data frame, and the responses into another data frame.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpP10NoqrOIA"
      },
      "source": [
        "questions = pd.read_csv('kaggle_survey_2020_responses.csv', header=[0], nrows=1)\n",
        "questions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFr5I0IQrGdg"
      },
      "source": [
        "responses = pd.read_csv('kaggle_survey_2020_responses.csv', header=[0], skiprows=[1])\n",
        "responses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBFLairArlTI"
      },
      "source": [
        "We're going to focus specifically on answers to machine learning-related questions, and exclude demographic information. Also, to make it easier, we'll just use the columns that are already essentially one-hot encoded.\n",
        "\n",
        "So, we will drop the following columns from the data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa85yGLwrwVO"
      },
      "source": [
        "drop_cols = ['Time from Start to Finish (seconds)', \n",
        "             'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q8', 'Q11', \n",
        "             'Q13', 'Q15', 'Q20', 'Q21', 'Q22', 'Q24', 'Q25', \n",
        "             'Q30', 'Q32', 'Q38']\n",
        "responses_sub = responses.drop(columns = drop_cols)\n",
        "questions_sub = questions.drop(columns = drop_cols)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3uAMQmOwgzT"
      },
      "source": [
        "responses_sub.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8TEx6mntr5p"
      },
      "source": [
        "Now, each column has only one possible value (or NaN). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FicYMOa3uASI"
      },
      "source": [
        "We can encode those values as 1s:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JmzorZGtrdI"
      },
      "source": [
        "responses_oh = responses_sub.notnull().astype('int')\n",
        "responses_oh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r7iV-b2uCjU"
      },
      "source": [
        "How do we interpret this data? \n",
        "\n",
        "To take an example: if the response value in row 0 is 1 for `Q7_Part_1`, this means that respondent 0 selected the first option for question 7. Looking at the survey questions and answers, we can see that this means they selected \"Python\" as a programming language they use on a regular basis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyBMyqU4Tze6"
      },
      "source": [
        "## Exploratory data analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_0b1isTYJXR"
      },
      "source": [
        "### To do 1: explore the data and look for high-level insight\n",
        "\n",
        "Later in this notebook, we'll use dimensionality reduction and clustering to try and gain some deeper insight into this data. First, though, see what you can find out from the high-dimensional data. \n",
        "\n",
        "Use exploratory data analysis to review the data and describe your high-level insights. According to the data, what are machine learning and data science enthusiasts using right now? What are they hoping to gain more experience with soon?\n",
        "\n",
        "Show your exploratory data analysis (code + output and visualizations) and also summarize your findings in  a text cell.\n",
        "\n",
        "(You can use either `responses_oh` or `responses_sub` for this step.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqHvS7NYGWPC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CCYMUpYWTIG"
      },
      "source": [
        "## Dimensionality reduction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "magTz8j_vTOy"
      },
      "source": [
        "Our ultimate goal is to gain deeper insight by clustering the respondents into \"cohorts\", and then looking at the state of machine learning and data science as described by each cohort separately.\n",
        "\n",
        "Because of the dimensionality of the data (hundreds of columns), it will not work very well with K-means clustering. K-means clustering also suffers from the curse of dimensionality: high dimensional data is often very sparse in the overall feature space, so that \"closest\" cluster mean to a particular sample may not really be much closer than the other cluster means.\n",
        "\n",
        "Also, since K-means clustering involves distance computations, it is expensive to apply to high-dimensional data.\n",
        "\n",
        "Finally, we want to be able to visually explore the data and the clusters, and it is very difficult to do this in hundreds of dimensions!\n",
        "\n",
        "To address this, we'll reduce the dimension of the data to 3D. This will help with clustering, and will also make it easier to visualize the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9CJ4l7XWYAS"
      },
      "source": [
        "### PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOUqbGWwwAwS"
      },
      "source": [
        "The \"classic\" dimensionality reduction method is PCA. Let's try to apply PCA to this data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPd7Ii3swJuH"
      },
      "source": [
        "#### To do 2: Apply PCA\n",
        "\n",
        "In the following cell, use the `sklearn` implementation of PCA. Create a PCA instance in a variable called `pca_reducer`, with `n_components = 3`. Then, fit it using the `responses_oh` data. Finally, use the `transform` method to project the `responses_oh` data into the 3D feature space learned by PCA. Save the result in a variable called `pca_responses`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjBGH5T8xDlI"
      },
      "source": [
        "# TODO 2\n",
        "\n",
        "# pca_reducer = ...\n",
        "# pca_responses = ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3vMJ5TmyZsa"
      },
      "source": [
        "Verify that the `pca_responses` dataset has reduced dimensionality:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6ZvyoJ4xUfI"
      },
      "source": [
        "pca_responses.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJoe993rxXEx"
      },
      "source": [
        "Let's visualize this result in 3D to see if it will make clustering easier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOZUQT5fxeF-"
      },
      "source": [
        "def plot_3D(elev=20, azim=20, pca_responses=pca_responses):\n",
        "\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = plt.axes(projection='3d')\n",
        "\n",
        "    ax.scatter3D(pca_responses[:,0], pca_responses[:,1], pca_responses[:,2], s=0.2);\n",
        "\n",
        "    ax.view_init(elev=elev, azim=azim)\n",
        "\n",
        "\n",
        "interact(plot_3D, elev=widgets.FloatSlider(min=-90,max=90,step=1, value=20),\n",
        "         azim=widgets.FloatSlider(min=-90,max=90,step=1, value=20),\n",
        "         pca_responses=fixed(pca_responses));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u75UpXOWzG0q"
      },
      "source": [
        "Use the elevation and azimuth sliders to view the data from different perspectives."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UB7iBtHPWYu3"
      },
      "source": [
        "### UMAP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ye7l4M5AxmKg"
      },
      "source": [
        "A more recent approach called UMAP is known to often produce better results for dimensionality reduction for visualization or clustering. \n",
        "\n",
        "Here are some useful resources for learning about UMAP:\n",
        "\n",
        "* [Understanding UMAP](https://pair-code.github.io/understanding-umap/)\n",
        "* [How UMAP works](https://umap-learn.readthedocs.io/en/latest/how_umap_works.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xp-FM3nByFOd"
      },
      "source": [
        "Let's try it! We can use `UMAP` in exactly the same way that we used `PCA` - specify the number of components as 3, fit the model using the `responses_oh` data, and then use the fitted model to transform the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kHDNil1yT0D"
      },
      "source": [
        "umap_reducer = UMAP(n_components=3).fit(responses_oh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beoBIeUHyict"
      },
      "source": [
        "umap_responses = umap_reducer.transform(responses_oh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDJUo4xIyfJv"
      },
      "source": [
        "Verify that the `umap_responses` dataset has reduced dimensionality:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCP2fU0FylEg"
      },
      "source": [
        "umap_responses.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW9ZGQ3wynxK"
      },
      "source": [
        "And let's plot this version of the data, too:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TkZcvhhyqEz"
      },
      "source": [
        "def plot_3D(elev=20, azim=20, umap_responses=umap_responses):\n",
        "\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    ax = plt.axes(projection='3d')\n",
        "\n",
        "    ax.scatter3D(umap_responses[:,0], umap_responses[:,1], umap_responses[:,2], s=0.2);\n",
        "\n",
        "    ax.view_init(elev=elev, azim=azim)\n",
        "\n",
        "\n",
        "interact(plot_3D, elev=widgets.FloatSlider(min=-90,max=90,step=1, value=20),\n",
        "         azim=widgets.FloatSlider(min=-90,max=90,step=1, value=20),\n",
        "         umap_responses=fixed(umap_responses));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd2pNnJEzLaE"
      },
      "source": [
        "Use the elevation and azimuth sliders to view the data from different perspectives."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2Kn2gzdyy9s"
      },
      "source": [
        "Which transformation of the data seems more useful for clustering?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "px_xopzLWa93"
      },
      "source": [
        "## Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJnguyGd0U6d"
      },
      "source": [
        "Next, let's use a clustering algorithm to try and define distinct \"cohorts\" among the respondents.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qElUDXOB0cKy"
      },
      "source": [
        "#### To do 3: apply a clustering algorithm\n",
        "\n",
        "Use a clustering algorithm from `sklearn` to find cohorts in the data. The following design choices are up to you:\n",
        "\n",
        "* You can apply the clustering to `pca_responses` or to `umap_responses` - whichever you think is most useful for clustering.\n",
        "* You can use `KMeans` or [any other clustering method](https://scikit-learn.org/stable/modules/clustering.html) implemented in `sklearn`. \n",
        "* You can decide how to initialize the cluster centers. Read the function documentation to learn about the initialization options available in the method you have chosen.\n",
        "* You can choose how many clusters to find, but you must have at least 3 clusters. Save the number of clusters in a variable called `n_clusters`.\n",
        "\n",
        "Save the cluster labels learned by your model in a variable called `c_responses`, and save the list of cluster centers in `c_centers`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxZXcM1i1iKX"
      },
      "source": [
        "# TODO 3\n",
        "\n",
        "# n_clusters = ....\n",
        "# c_responses = ...\n",
        "# c_centers = ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVu3UIpm2QXa"
      },
      "source": [
        "Let's visualize the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rmWBPRS2fhp"
      },
      "source": [
        "If you used the PCA-transformed data, use this function to visualize the results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVM0D-9r3n5a"
      },
      "source": [
        "def plot_3D(elev=20, azim=20, pca_responses=pca_responses, n_clusters=n_clusters,\n",
        "            c_responses=c_responses, c_centers=c_centers):\n",
        "\n",
        "    fig = plt.figure(figsize=(15,10))\n",
        "    ax = plt.axes(projection='3d')\n",
        "\n",
        "    cmap = plt.cm.Dark2\n",
        "    norm = colors.BoundaryNorm(np.arange(0, n_clusters+1, 1), cmap.N)\n",
        "\n",
        "    p = ax.scatter3D(pca_responses[:,0], pca_responses[:,1], pca_responses[:,2], \n",
        "                 c=c_responses, s=0.2, alpha=0.4, cmap=cmap, norm=norm);\n",
        "    fig.colorbar(p)\n",
        "    # note: you can adjust the value of s here to change the size of the cluster centers\n",
        "    p = ax.scatter3D(c_centers[:,0], c_centers[:,1], c_centers[:,2], edgecolor='black',\n",
        "                 c=range(n_clusters), s=100, cmap=cmap, norm=norm);\n",
        "\n",
        "    ax.view_init(elev=elev, azim=azim)\n",
        "\n",
        "\n",
        "interact(plot_3D, elev=widgets.FloatSlider(min=-90,max=90,step=1, value=20),\n",
        "         azim=widgets.FloatSlider(min=-90,max=90,step=1, value=20),\n",
        "         pca_responses=fixed(pca_responses),  n_clusters=fixed(n_clusters),\n",
        "         c_responses=fixed(c_responses), c_centers=fixed(c_centers));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkxpHAXO2l42"
      },
      "source": [
        "If you used the UMAP-transformed data, use this function to visualize the results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btCFZPYF2R66"
      },
      "source": [
        "def plot_3D(elev=20, azim=20, umap_responses=umap_responses, n_clusters=n_clusters,\n",
        "            c_responses=c_responses, c_centers=c_centers):\n",
        "\n",
        "    fig = plt.figure(figsize=(15,10))\n",
        "    ax = plt.axes(projection='3d')\n",
        "\n",
        "    cmap = plt.cm.Dark2\n",
        "    norm = colors.BoundaryNorm(np.arange(0, n_clusters+1, 1), cmap.N)\n",
        "\n",
        "    p = ax.scatter3D(umap_responses[:,0], umap_responses[:,1], umap_responses[:,2], \n",
        "                 c=c_responses, s=0.2, alpha=0.4, cmap=cmap, norm=norm);\n",
        "    fig.colorbar(p)\n",
        "    # note: you can adjust the value of s here to change the size of the cluster centers\n",
        "    p = ax.scatter3D(c_centers[:,0], c_centers[:,1], c_centers[:,2], edgecolor='black',\n",
        "                 c=range(n_clusters), s=100, cmap=cmap, norm=norm);\n",
        "\n",
        "    ax.view_init(elev=elev, azim=azim)\n",
        "\n",
        "\n",
        "interact(plot_3D, elev=widgets.FloatSlider(min=-90,max=90,step=1, value=20),\n",
        "         azim=widgets.FloatSlider(min=-90,max=90,step=1, value=20),\n",
        "         umap_responses=fixed(umap_responses),  n_clusters=fixed(n_clusters),\n",
        "         c_responses=fixed(c_responses), c_centers=fixed(c_centers));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6k0WF6mx6zva"
      },
      "source": [
        "Are you satisfied with your clusters? Do the cluster centers look like a good representation of the samples in the cluster?\n",
        "\n",
        "Adjust your clustering (you can change the intialization, the number of clusters, or the clustering algorithm) until you are satisfied with the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Izd0kIaV4NqE"
      },
      "source": [
        "### To do 4: Apply inverse transform to the cluster centers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDeF_tW65Y-s"
      },
      "source": [
        "Next, we'll look at the cluster centers in the original high-dimensional feature space. \n",
        "\n",
        "Use the `inverse_transform` method of your reducer (either the `pca_reducer` or the `umap_reducer`, depending on which type of transformed data you used for clustering). Apply this to the `c_centers` variable to get the cluster centers in the original high-dimensional feature space. Save the result in `c_centers_highd`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqF8QIS7-9sF"
      },
      "source": [
        "# TODO 4\n",
        "\n",
        "# c_centers_highd = ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIiQGMzX_ar4"
      },
      "source": [
        "Now, we can look at the cluster centers in the high dimensional feature space to see what the \"typical\" survey answers are for each cluster."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de4giJSp_i5W"
      },
      "source": [
        "plt.figure(figsize=(15,n_clusters*2))\n",
        "for i, c in enumerate(c_centers_highd):\n",
        "  plt.subplot(n_clusters,1,i+1)\n",
        "  plt.stem(c, use_line_collection=True, markerfmt='.');\n",
        "  plt.ylim(-0.5, 1.25) # adjust this as needed to display the data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFxOv8_iCXwH"
      },
      "source": [
        "A value close to 0 for a particular feature means that most respondents in the cluster did *not* select that option. A value close to 1 for a feature means that most respondents in the cluster *did* select that option."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZkWMDK_WcBz"
      },
      "source": [
        "## Cohort analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9pMDErmClZK"
      },
      "source": [
        "#### To do 5: use the cluster centers in high dimension feature space to explore cohorts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVr5bF1tCqhb"
      },
      "source": [
        "Use the `c_centers_highd`, the cluster labels `c_responses`, and the original data (either `responses`, `responses_sub`, or `responses_oh`) to explore *each cluster* in greater detail.\n",
        "\n",
        "For each cluster, see if you can identify:\n",
        "\n",
        "* What do members of the cluster tend to have in common?\n",
        "* What do members of the cluster say about the state of machine learning and data science? What tools and techniques do they often use? What are they hoping to use?\n",
        "* Is the cluster center a good representation of the cluster members?\n",
        "\n",
        "Also note any important differences between clusters. \n",
        "\n",
        "Use this analysis to draw high-level conclusions about the state of machine learning and data science.\n",
        "\n",
        "Show your analysis (code + output and visualizations) and also summarize your findings in one or more text cells.\n",
        "\n",
        "At the end, please summarize your findings with a brief description of each \"cohort\" that you found.\n",
        "\n",
        "(To help you understand the level of effort expected - this section is worth 4/10 points for this assignment. For full credit, the graders will expect to see an analysis of sufficient detail to justify this point value.)"
      ]
    }
  ]
}